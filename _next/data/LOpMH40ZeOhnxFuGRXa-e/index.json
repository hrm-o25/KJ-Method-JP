{"pageProps":{"result":{"clusters":[{"cluster":"産学連携と実務教育の進化","cluster_id":"6","takeaways":"現在の研究開発体制には、シーズの発掘から成果の活用までを一貫して管理する仕組みが欠けており、企業が研究成果を独占できないため、特許に関する複雑な権利関係や莫大な実施料の支払い義務が生じることがあります。特に、共同研究においては権利関係のトラブルが発生することがあり、小野薬品と本庶佑氏のオプジーボ訴訟がその一例です。また、実用化に向けた技術シーズの情報発信が不足しており、企業が新技術をキャッチアップするのが難しい状況です。\n\nさらに、技術指導や共同研究契約の手続きが煩雑で、ルールやマネジメントが不十分なため、営業秘密や利益造反行為のリスクも存在します。図書館や食堂は一般利用可能ですが、法律は所有権者を決定するものの、需要に応じた解決策を提供できていません。メーカーは量産化から販売までのリスクを負う一方で、研究はリスクが少ないように見えるため、インターンシップの参加が打算的な動機に基づくこともあります。","arguments":[{"arg_id":"A0_0","argument":"シーズの発掘から成果の活用まで一貫して管理する体制がない。","comment_id":"0","x":18.320765,"y":4.550996,"p":1},{"arg_id":"A3_0","argument":"自社の研究施設を持つことが可能である（例：GAFA、NTT、野村総研）。","comment_id":"3","x":18.52826,"y":5.3695474,"p":1},{"arg_id":"A5_0","argument":"特許等の研究成果を企業が独占できない","comment_id":"5","x":18.307053,"y":4.943426,"p":1},{"arg_id":"A5_1","argument":"企業が研究成果を独占した場合、莫大な実施料の支払い義務を負う","comment_id":"5","x":18.33923,"y":5.027224,"p":1},{"arg_id":"A9_0","argument":"共同研究において権利関係で揉めることがある","comment_id":"9","x":18.16891,"y":5.044468,"p":1},{"arg_id":"A9_1","argument":"小野薬品と本庶佑氏のオプジーボ訴訟がその例である","comment_id":"9","x":18.849445,"y":4.872696,"p":1},{"arg_id":"A11_0","argument":"実用化に繋がりそうな技術シーズの情報発信が少なく、企業がキャッチアップしづらい。","comment_id":"11","x":18.29483,"y":4.494019,"p":0.8069130572736193},{"arg_id":"A12_0","argument":"技術指導・共同研究契約の手続きが煩雑である。","comment_id":"12","x":18.507751,"y":4.6992297,"p":1},{"arg_id":"A13_0","argument":"共同研究・委託研究に関するルール・マネジメントが不十分であり、営業秘密や利益造反行為のリスクが存在する。","comment_id":"13","x":18.4438,"y":4.7888618,"p":1},{"arg_id":"A29_0","argument":"図書館は一般利用可能である","comment_id":"29","x":17.71952,"y":5.136161,"p":1},{"arg_id":"A29_1","argument":"食堂は一般利用可能である","comment_id":"29","x":17.588963,"y":5.2415857,"p":0},{"arg_id":"A31_0","argument":"法律はオレンジの所有権者を決めることができるが、需要に応じた解決策を提供できない。","comment_id":"31","x":17.950562,"y":4.878699,"p":1},{"arg_id":"A80_0","argument":"メーカーは量産化から販売までリスクを負うが、研究はリスクが少ないように映る。","comment_id":"80","x":18.81459,"y":5.3932505,"p":0.8101665361152408},{"arg_id":"A81_1","argument":"インターンシップを行う行動は打算的で、履歴書に書くためのものであった。","comment_id":"81","x":18.937914,"y":4.860831,"p":1},{"arg_id":"A85_0","argument":"図書館の開架図書コーナーには地域のおじいちゃんがいた。","comment_id":"85","x":19.195398,"y":4.900117,"p":1}]},{"cluster":"産学連携と研究資金の新たなモデル","cluster_id":"4","takeaways":"大学発ベンチャーが製薬企業に買収される一方で、国立大学は研究費の調達に苦しんでおり、企業からの寄付講座がなければ研究の存続が難しい状況です。このため、民間から資金が得やすい研究テーマに偏りがちで、産学連携は研究費には寄与するものの、大学の運営費にはつながらないという課題があります。また、大学院生は経済支援が不透明で、アルバイトに多くの時間を費やさざるを得ないカリキュラムが問題視されています。\n\nさらに、成績連動型奨学金は学生にプレッシャーを与え、大学の学費の値上げが必要とされています。補助金申請の負担が研究や教育の時間を削る原因となり、若手研究者の疲弊を招いています。労働のあり方についても、時間当たりの採算を重視する社会人の視点が求められ、学生には目標を決めずに迷う時間を与えるべきとの意見もあります。","arguments":[{"arg_id":"A1_0","argument":"大学発ベンチャーが製薬企業に買収され、自社の研究部門として活用される。","comment_id":"1","x":19.115517,"y":5.7311344,"p":0},{"arg_id":"A7_0","argument":"国立大学も自前で研究費の調達が必要であり、企業からの寄付講座がないと研究の存続が厳しい。","comment_id":"7","x":18.772842,"y":5.9728966,"p":0},{"arg_id":"A7_1","argument":"民間から資金が得やすい研究テーマだけが継続される傾向がある。","comment_id":"7","x":18.294989,"y":5.7331424,"p":0},{"arg_id":"A8_0","argument":"学内または大学の近くに大学発ベンチャーが存在する。","comment_id":"8","x":19.478333,"y":6.1787868,"p":0},{"arg_id":"A10_0","argument":"産学連携は研究費としては機能するが、大学の運営費にはならない。","comment_id":"10","x":18.848188,"y":5.874378,"p":0},{"arg_id":"A16_0","argument":"諸外国の大学院では、授業料を支払うのではなく、院生に給料が支給されるのが普通である。","comment_id":"16","x":18.71166,"y":6.7726955,"p":0.6577872741470019},{"arg_id":"A17_0","argument":"大学・大学院での経済支援が不透明であり、学生がアルバイトに多くの時間を費やさざるを得ないカリキュラムになっていない。","comment_id":"17","x":18.498972,"y":6.517896,"p":0.9724378281378429},{"arg_id":"A20_0","argument":"成績連動型奨学金は、成績を落とせないというプレッシャーを常に与える。","comment_id":"20","x":18.312918,"y":6.6600904,"p":1},{"arg_id":"A21_0","argument":"大学の学費自体を値上げする必要がある。","comment_id":"21","x":18.908365,"y":6.521856,"p":0.6577872741470019},{"arg_id":"A36_0","argument":"労働時間でカウントすると個人差がある。","comment_id":"36","x":17.79974,"y":6.468502,"p":1},{"arg_id":"A38_1","argument":"大学教員は特権的な時間の自由を世間の常識とは異なる価値観で活用する必要がある。","comment_id":"38","x":18.651567,"y":7.1335754,"p":0},{"arg_id":"A40_0","argument":"国が大学セクターを動かすために補助金をばら撒くことが、若手研究者の疲弊を招く。","comment_id":"40","x":18.609299,"y":6.327446,"p":0.6369972279175476},{"arg_id":"A40_1","argument":"補助金申請に伴う作業が研究・教育時間を削る原因となっている。","comment_id":"40","x":18.298792,"y":6.182897,"p":0.7972327005474884},{"arg_id":"A41_0","argument":"専門業務型裁量労働者とは、特定の専門的な業務に従事し、労働時間や業務の進め方について一定の裁量を持つ労働者を指す。","comment_id":"41","x":17.680952,"y":6.7790627,"p":0.8212104923415608},{"arg_id":"A46_0","argument":"学生に目標を決めずに迷う時間を与えるべきである。","comment_id":"46","x":18.190174,"y":6.835429,"p":0.7209689984228307},{"arg_id":"A49_0","argument":"労働は生命を維持するために実施されるべきである","comment_id":"49","x":17.350008,"y":6.507583,"p":0},{"arg_id":"A49_1","argument":"労働は単一性と私的な側面を持つ","comment_id":"49","x":17.35928,"y":6.750749,"p":0.8212104923415608},{"arg_id":"A50_0","argument":"社会人は時間当たり採算を重視すべきである。","comment_id":"50","x":17.44104,"y":6.130812,"p":0},{"arg_id":"A51_0","argument":"限られた時間で成果を出すことが求められる。","comment_id":"51","x":17.638245,"y":6.319676,"p":1},{"arg_id":"A82_0","argument":"給付型奨学金は振込先によっては両親から使い込まれることがある","comment_id":"82","x":18.414253,"y":6.6407022,"p":1},{"arg_id":"A82_1","argument":"その結果、学生はアルバイトに多くの時間を費やすことになる","comment_id":"82","x":17.932405,"y":6.549635,"p":0.8021815008161942},{"arg_id":"A93_0","argument":"研究室のドアを外して暖簾に変更するべきである。","comment_id":"93","x":18.917181,"y":6.4620023,"p":0.6369972279175476},{"arg_id":"A96_1","argument":"民間の研究所では研究に専念でき、リサーチ予算が大学の10倍である。","comment_id":"96","x":18.5288,"y":5.603219,"p":1},{"arg_id":"A97_0","argument":"華道はシングルマザーとしての疲れを癒す役割を果たした。","comment_id":"97","x":17.847176,"y":6.0802155,"p":0.8592190321614283},{"arg_id":"A97_1","argument":"華道は役に立たないが、無駄な時間が救いになった。","comment_id":"97","x":18.051216,"y":6.1304393,"p":0.8592190321614283}]},{"cluster":"コミュニティ形成とAI活用の進展","cluster_id":"3","takeaways":"経済的なコミュニティの形成や多様な関わり方の重要性が強調されており、特にコモニングやDAOの概念が注目されています。コモニングは参加者同士の受け入れ合いを重視し、DAOはプロトコルに基づく行動調整を促進します。また、AIの活用が教育や研究において重要視され、社会貢献として地域や国際的な課題への寄与が求められています。\n\nオンライン環境でのコミュニケーションは、心理的安全性を高める一方で、一方的な主張や気遣いの難しさも指摘されています。多様な意見を交換する共創空間の必要性や、異なる文化を持つ人々の知の共有が重要であるとされ、特にコロナ禍においてはオンラインでの交流が活発化しています。","arguments":[{"arg_id":"A2_0","argument":"経済的なコミュニティを形成することが重要である。","comment_id":"2","x":17.067728,"y":5.610887,"p":0.7262877139512214},{"arg_id":"A22_0","argument":"多様な関わり方の余白を広げていくことが重要である。","comment_id":"22","x":16.858835,"y":5.4660563,"p":0.944911326041458},{"arg_id":"A23_0","argument":"コモニングは気ままに参加し、受け入れ合い、管理する関係性的で実践的なプロセスである。","comment_id":"23","x":16.65348,"y":5.089867,"p":1},{"arg_id":"A24_0","argument":"DAOはプロトコルを中心にしたエコシステムであり、人々の行動がそのプロトコルに基づいて調整されている。","comment_id":"24","x":16.266005,"y":5.1476083,"p":1},{"arg_id":"A24_1","argument":"DAOに参加することでトークンを得ることができる。","comment_id":"24","x":16.048674,"y":4.939602,"p":0.946048602320952},{"arg_id":"A25_0","argument":"AIは人間の直接的な介入なしに、定められたルールに基づいて行動できる。","comment_id":"25","x":16.302067,"y":5.762432,"p":0},{"arg_id":"A25_1","argument":"AIの行動には参加者の綿密なコミュニケーションや相互理解は不要である。","comment_id":"25","x":16.290472,"y":5.4936495,"p":1},{"arg_id":"A27_0","argument":"人々がコモンズとしての意識を持ち、行動や交渉を通じてそれを形作ることが重要である。","comment_id":"27","x":16.74692,"y":5.286994,"p":1},{"arg_id":"A28_0","argument":"Web3はユーザーからステークホルダーへの移行を促進する。","comment_id":"28","x":16.081217,"y":4.9329925,"p":1},{"arg_id":"A30_0","argument":"寮をクリエイターコミュニティとして貸出することを希望する。","comment_id":"30","x":17.40294,"y":5.454722,"p":0},{"arg_id":"A33_0","argument":"オンラインのつながりは便利で効率的であるが、人間関係が出来上がった人や意見を同じくする人同士で集まりがちである。","comment_id":"33","x":15.629014,"y":5.30396,"p":0.5760346640592953},{"arg_id":"A43_0","argument":"教育においてAIの活用が重要である","comment_id":"43","x":16.784498,"y":6.03625,"p":1},{"arg_id":"A43_1","argument":"研究においてAIの役割が拡大している","comment_id":"43","x":16.74249,"y":5.767941,"p":1},{"arg_id":"A43_2","argument":"社会貢献としてAIが地域、経済、国際的な課題に寄与するべきである","comment_id":"43","x":16.676441,"y":5.861787,"p":1},{"arg_id":"A44_1","argument":"常識をアンロックすることが重要である","comment_id":"44","x":16.580963,"y":6.2434483,"p":0.9218940059669762},{"arg_id":"A53_0","argument":"他者との共同行為、特に言葉を用いたコミュニケーションが重要である","comment_id":"53","x":16.591377,"y":5.3157477,"p":1},{"arg_id":"A53_1","argument":"複数性と公共性が活動において重要な要素である","comment_id":"53","x":17.033545,"y":5.290156,"p":0.944911326041458},{"arg_id":"A58_0","argument":"公共的な問題について話し合い、複数的な意見を交換する共創空間が必要である。","comment_id":"58","x":17.151382,"y":5.1429462,"p":0},{"arg_id":"A60_0","argument":"様々な国、文化を持つ人々の知の共有と交流が重要である。","comment_id":"60","x":17.093256,"y":6.002238,"p":0},{"arg_id":"A87_0","argument":"コロナ下での入学により、Web3に関心のある仲間とのオンライン交流が活発であるが、主張が一方的になることがある。","comment_id":"87","x":15.760432,"y":5.0572596,"p":0.9141451965999008},{"arg_id":"A88_0","argument":"コロナ下でのオンラインゼミでは、思ったよりも闊達な議論が可能であった。","comment_id":"88","x":15.458389,"y":5.324073,"p":0.982303046630082},{"arg_id":"A88_1","argument":"オンラインゼミでは、顔色を窺わないことで発言することへの心理的安全性が上がった可能性がある。","comment_id":"88","x":15.551667,"y":5.3005295,"p":1},{"arg_id":"A88_2","argument":"一方で、相手を見ているようで自分の話をしているというコミュニケーションになっている。","comment_id":"88","x":16.239183,"y":5.4309425,"p":1},{"arg_id":"A88_3","argument":"オンライン環境では気を遣うのが難しいかもしれない。","comment_id":"88","x":15.471917,"y":5.3512278,"p":1}]},{"cluster":"大学の地域社会との連携と多機能性の強化","cluster_id":"5","takeaways":"大学は、地域に新たな若者を供給し、企業や投資家が集まるコモンズ空間として機能しています。近代の大学は、学生と教師の協同組合として自由な移動を促進し、都市の中で新たな教育の場を創出しています。特にミネルヴァ大学のように、伝統的なキャンパスを持たず、学生が世界各地を移動しながら学ぶスタイルは、現代の教育の多様性を象徴しています。\n\nまた、大学教育は高等教育の質の確保が課題となる中で、国力強化や文化復興の基盤として再定義されるべきです。文系と理系の教育環境を整え、学生と教師が共に学ぶ場を提供することが求められています。現代の大学は、教育・研究・奉仕の多機能を持つ「マルチバーシティ」として、学生に新たな選択肢を提供する重要な役割を果たしています。","arguments":[{"arg_id":"A4_0","argument":"大学の近くに企業や投資家が集まる傾向がある。","comment_id":"4","x":19.489588,"y":6.3391156,"p":0},{"arg_id":"A26_0","argument":"大学はコモンズ空間であり、誰かに所有された空間ではなく、行動や交渉を通じて形作られる空間である。","comment_id":"26","x":19.18354,"y":7.3109894,"p":0},{"arg_id":"A45_0","argument":"地方大学は、地域に新たな若者（働き手）を供給している。","comment_id":"45","x":19.752052,"y":6.83857,"p":1},{"arg_id":"A66_0","argument":"近代の大学は学生と教師の協同組合として機能し、自由な移動を促進する一方で、都市支配層との関係が存在する。","comment_id":"66","x":19.929869,"y":7.103637,"p":0.7513089438230038},{"arg_id":"A67_0","argument":"教会や広場などの都市施設を利用して授業を実施することが、新たな大学を都市の中に生み出す要因となる。","comment_id":"67","x":19.866793,"y":6.7991824,"p":1},{"arg_id":"A67_1","argument":"この集団が都市から都市へと渡り歩くことで、次々と新たな大学が形成される。","comment_id":"67","x":19.93625,"y":6.8572874,"p":1},{"arg_id":"A68_0","argument":"ミネルヴァ大学は2012年にアメリカで設立され、伝統的なキャンパスを持たず、学生は世界各地を移動しながら学ぶ。","comment_id":"68","x":19.46158,"y":7.1637707,"p":1},{"arg_id":"A68_1","argument":"ミネルヴァ大学は学問的なカリキュラム（オンライン）と異文化体験（寮が世界各国にある）を融合させた教育を提供している。","comment_id":"68","x":19.329357,"y":7.202789,"p":1},{"arg_id":"A69_1","argument":"大学教育は18歳人口の急激な減少や高等学校教育の多様化により、高等教育の質の確保が大きな課題となっている。","comment_id":"69","x":20.090532,"y":7.6936407,"p":0},{"arg_id":"A72_0","argument":"大学は自国の文化復興のための国民国家の基盤として再定義されるべきである。","comment_id":"72","x":19.541027,"y":7.02234,"p":0.9556154118833344},{"arg_id":"A74_0","argument":"文系におけるゼミナールと理系における実験室を確立し、学生と教師が共に学ぶ環境を作るべきである。","comment_id":"74","x":19.235523,"y":7.594804,"p":1},{"arg_id":"A75_0","argument":"日本の大学設立の目的は国力強化であり、近代化の装置として機能する。","comment_id":"75","x":19.90497,"y":7.116374,"p":0.709461902316332},{"arg_id":"A75_1","argument":"日本の大学は国益に直結するエリート養成学校としての役割を果たすべきである。","comment_id":"75","x":19.313862,"y":6.9683313,"p":0.7336975779223036},{"arg_id":"A76_0","argument":"オルテガによると、1930年代スペインにおける大学の使命は、教養教育、専門職業人の養成、科学の推進である。","comment_id":"76","x":19.994717,"y":7.419569,"p":0},{"arg_id":"A77_0","argument":"現代の大学は教育・研究・奉仕の多機能を持った「マルチバーシティ」である。","comment_id":"77","x":19.727129,"y":7.6462226,"p":0},{"arg_id":"A100_2","argument":"大学は学生に新たな選択肢を提供する場所である。","comment_id":"100","x":19.501698,"y":7.198404,"p":1}]},{"cluster":"国際的な連携とキャリア支援の強化","cluster_id":"1","takeaways":"留学生の受け入れは、海外企業とのつながりを生み出し、教育への投資意欲を高める要因となります。大卒者は非大卒者に比べて年収が高く、大学進学へのハードルが低いため、良い大学を選ぶことが就職後の階層関係に影響を与えるとされています。また、大学は学生と教員が互いに学び合う場であり、文理融合を進めることが重要です。リカレント教育やPBL型教育の導入も、実践的なスキル向上に寄与します。\n\nさらに、大学教員は知的なロールモデルとしての役割を果たし、研究と教育を両立させることが求められます。特に、社会人経験を持つ教授の招聘や、偏差値重視ではない新しい入試基準の導入が必要とされています。留学経験は語学力向上だけでなく、異文化理解を深める貴重な機会であり、学生にとって重要な成長の場となります。","arguments":[{"arg_id":"A6_0","argument":"留学生を受け入れることで海外企業とのつながりを創出できる。","comment_id":"6","x":18.21035,"y":7.2837586,"p":0},{"arg_id":"A18_1","argument":"大卒のメリット（就職のしやすさなど）を理解しているため、子供に教育を投資する意欲が高い。","comment_id":"18","x":17.79507,"y":8.101154,"p":1},{"arg_id":"A18_3","argument":"非大卒者に比べて年収が高いため、大学進学への金銭的・心理的ハードルが低い。","comment_id":"18","x":17.853415,"y":7.979495,"p":1},{"arg_id":"A35_0","argument":"就職後の階層関係を意識して良い大学を選ぶべきである。","comment_id":"35","x":18.397758,"y":7.6948376,"p":1},{"arg_id":"A37_0","argument":"学生と教師が結びつき、学生は教養と研究を行い、教師は研究と教育を行うべきである","comment_id":"37","x":19.122057,"y":8.334243,"p":1},{"arg_id":"A37_1","argument":"事務職は金策を練ったり、大学としてのブランディングを実施するべきである","comment_id":"37","x":18.571846,"y":7.5350223,"p":0.9364135198933948},{"arg_id":"A38_0","argument":"大学教員がロールモデルになるには、知的にかっこよくあるべきである。","comment_id":"38","x":18.762508,"y":7.809417,"p":0.8271468856438529},{"arg_id":"A38_2","argument":"大学教員はクリエイティブな価値観を示し、博覧強記のかっこよさを持つべきである。","comment_id":"38","x":19.059793,"y":7.654407,"p":1},{"arg_id":"A39_0","argument":"研究者の魅力は、世間や時代に合わせず自己本位を貫くところにある。","comment_id":"39","x":18.64971,"y":8.640226,"p":1},{"arg_id":"A39_1","argument":"研究者は趣味的な職業人である点が魅力である。","comment_id":"39","x":18.59999,"y":8.80486,"p":1},{"arg_id":"A42_0","argument":"社会人キャリアのある人を教授として招聘するべきである。","comment_id":"42","x":18.516012,"y":7.8248367,"p":1},{"arg_id":"A52_0","argument":"リカレント教育は、学び直しやスキルの向上を促進する重要な手段である。","comment_id":"52","x":19.40624,"y":8.133402,"p":0.9377701165763948},{"arg_id":"A54_0","argument":"大学は、生活の心配をせずに問いを持ち、深く考え、対話する場である。","comment_id":"54","x":19.154694,"y":7.6200805,"p":1},{"arg_id":"A55_0","argument":"大学の使命は文理融合を進めることであり、専門分野を複数持つことがそれぞれの分野に役立つ。","comment_id":"55","x":19.367878,"y":8.034191,"p":0.9377701165763948},{"arg_id":"A55_1","argument":"数学者岡潔の言葉「数学の中心は情緒」を通じて、数学と文学の融合の重要性が示されている。","comment_id":"55","x":19.51131,"y":7.9038887,"p":1},{"arg_id":"A70_0","argument":"就職先は大卒であることよりも、どこの大学を出ているのかが重要である。","comment_id":"70","x":18.267355,"y":7.945475,"p":1},{"arg_id":"A71_0","argument":"18歳人口の6割が大学や短大に進学していることは、一部のエリートのためのものではない。","comment_id":"71","x":19.351278,"y":7.8177896,"p":0.8372910545660833},{"arg_id":"A73_0","argument":"フンボルト的大学観は、研究と教育を一体として結合させ、大学人を第一義的に研究者とし、研究成果の披瀝が最高の教育であるとする考え方である。","comment_id":"73","x":19.667624,"y":7.81412,"p":1},{"arg_id":"A78_0","argument":"PBL型教育は、実践的な問題解決を通じて学習を促進する教育手法である。","comment_id":"78","x":19.52437,"y":8.241334,"p":0},{"arg_id":"A79_0","argument":"偏差値重視の受験内容ではなく、新しい入試の基準が必要である。","comment_id":"79","x":18.078276,"y":7.905811,"p":1},{"arg_id":"A89_0","argument":"大学の学部は就職に役立つことを重視して選んだ。","comment_id":"89","x":18.379635,"y":8.285535,"p":0},{"arg_id":"A89_1","argument":"外大を選ぶことで空港で働く可能性があると考えている。","comment_id":"89","x":17.818247,"y":7.8551626,"p":1},{"arg_id":"A95_0","argument":"T教授は研究、管理、教育の三役をこなす優秀な研究者であるが、それは至難の業である。","comment_id":"95","x":19.091234,"y":8.407893,"p":1},{"arg_id":"A96_0","argument":"研究と教育を両立できる人がいるが、書類仕事が多く、大学を辞めて民間の研究所に行った。","comment_id":"96","x":18.987574,"y":8.62977,"p":1},{"arg_id":"A98_0","argument":"私の大学院卒業代のトップは社会人学生であり、自衛官である。","comment_id":"98","x":18.308352,"y":8.340663,"p":0.9769049968305044},{"arg_id":"A100_0","argument":"外大では在学中の海外留学が当たり前であり、地元高校では想像できなかった文化に触れることができる。","comment_id":"100","x":17.944763,"y":7.5317802,"p":1},{"arg_id":"A100_1","argument":"留学を通じて語学力の向上だけでなく、異文化に触れる驚きや喜びを知り、それぞれの土地の文化や特産品の魅力を広めたい。","comment_id":"100","x":18.13581,"y":7.3283772,"p":1}]},{"cluster":"実学重視と学問の多様性の調和","cluster_id":"7","takeaways":"現在の教育環境では、実学偏重の傾向が強まり、学力で難関大学に入学しても、教養や生活面での差を感じることが多い。親が大学卒業者である場合、子どもも同様の道を歩む傾向があり、意図的な養育を通じて子どもの自発性を促すことが一般的である。一方で、大学生活では同級生とのコミュニケーションが難しく、特に哲学や宗教などの学問は就職との関連が薄いと感じられている。\n\nしかし、一般教養科目では異なる学部の学生と交流することで、学びの楽しさを実感することができる。特に、個人的な意見を表現できる授業が印象に残り、大学生活の「余白」を楽しむことが重要であると認識されている。研究科に進むことで、教授や先輩後輩との距離が縮まり、同じ興味を持つ仲間と出会う機会が増えることが期待されている。","arguments":[{"arg_id":"A7_2","argument":"実学偏重の傾向が見られる。","comment_id":"7","x":17.74706,"y":8.822184,"p":0.6784754786900452},{"arg_id":"A14_0","argument":"学力で難関大学に入れても、教養面や生活面で差を感じる機会が多い。","comment_id":"14","x":17.397758,"y":8.522501,"p":1},{"arg_id":"A18_0","argument":"親が大卒であると、子も大卒になりやすい傾向がある。","comment_id":"18","x":17.605164,"y":8.383104,"p":1},{"arg_id":"A18_2","argument":"習い事を通じて子供の自発性を促す意図的養育が行われることが多い。","comment_id":"18","x":17.809372,"y":8.514264,"p":0},{"arg_id":"A57_0","argument":"実学から離れたところで、好奇心の赴くままに好きなことを学ぶことが重要である。","comment_id":"57","x":17.913784,"y":8.9697485,"p":1},{"arg_id":"A86_0","argument":"同級生は恋バナについて話している。","comment_id":"86","x":17.041353,"y":9.297111,"p":1},{"arg_id":"A86_1","argument":"同級生は推しのアイドルについて話している。","comment_id":"86","x":17.150618,"y":9.278054,"p":1},{"arg_id":"A86_2","argument":"同級生はMBTIについて話している。","comment_id":"86","x":17.176771,"y":9.344679,"p":1},{"arg_id":"A87_1","argument":"直接会うことがないため、教授や同級生との親密な関係を築きにくい。","comment_id":"87","x":17.467518,"y":8.997058,"p":0},{"arg_id":"A89_2","argument":"哲学などの学部は就職と結びつきにくいと感じている。","comment_id":"89","x":17.475336,"y":8.880055,"p":0.6291737984780125},{"arg_id":"A90_0","argument":"夫が学生時代に印象に残った授業は「山陰の歴史」と「宗教と死生観」であり、工学とは異質な感じが良かった。","comment_id":"90","x":18.248081,"y":9.37123,"p":0},{"arg_id":"A90_1","argument":"工学系のレポートには私見がないが、これらの授業では私見を入れることができた。","comment_id":"90","x":18.456316,"y":9.283247,"p":0},{"arg_id":"A91_0","argument":"大学には「余白」を楽しみに行った。","comment_id":"91","x":18.333694,"y":8.664078,"p":1},{"arg_id":"A92_0","argument":"一般教養科目では、さまざまな学部学科の人と交わることで、1年目の授業が一番楽しかった。","comment_id":"92","x":18.067556,"y":9.052862,"p":1},{"arg_id":"A99_1","argument":"哲学や宗教系の学問に興味を持っているが、年齢差からくる心理的な障壁がある。","comment_id":"99","x":17.690672,"y":9.267791,"p":0},{"arg_id":"A101_0","argument":"研究科に入ると、先生や先輩後輩との距離が近くなり、同じ学問を追求する仲間ができる。","comment_id":"101","x":17.931183,"y":9.002386,"p":1}]},{"cluster":"社会的期待と個人の成長の交差点","cluster_id":"2","takeaways":"裕福な層でも将来の選択肢が限られ、親の期待や社会の眼差しがプレッシャーとなることが多い。特に、進学においては周囲からの敬意が得られないと努力が報われず、運に左右されることもある。福沢諭吉は、貧困層に高等教育が不要とする考えに警鐘を鳴らし、智力の成長が実際の地位や財産に結びつかないと社会の安寧が脅かされると指摘している。\n\nまた、キャンパスライフの重要性や、女性が意思決定に参加できる環境の必要性も強調されている。大学生は就職への焦りからインターンを始めることが多く、心の貧しさや社会への危機感を抱えながら、切羽詰まった状況で進学を目指す。大人になってから学びたいことを学べる場があれば、幸福度が向上する可能性があることも示唆されている。","arguments":[{"arg_id":"A14_1","argument":"裕福な層が楽をしているわけではなく、将来の選択肢が限られている。","comment_id":"14","x":17.144258,"y":7.5382166,"p":0},{"arg_id":"A14_2","argument":"親の期待値の高さがプレッシャーとなり、生育環境が人生のしがらみとなる。","comment_id":"14","x":17.038616,"y":8.012598,"p":1},{"arg_id":"A15_0","argument":"人間は社会性の生き物であり、他者からの眼差しによって自分のありようを決めてしまい、不自由を感じることがある。","comment_id":"15","x":16.14986,"y":7.1039295,"p":0.7455237436329877},{"arg_id":"A19_0","argument":"周囲に敬意を払われない状態で努力を続けることは、進学において困難を伴う","comment_id":"19","x":17.177559,"y":8.156903,"p":1},{"arg_id":"A19_1","argument":"運が良くないと進学できない可能性がある","comment_id":"19","x":17.281305,"y":7.9384313,"p":1},{"arg_id":"A31_1","argument":"法律だけを学んでいても、社会では通用しない。","comment_id":"31","x":16.88865,"y":6.9382267,"p":0},{"arg_id":"A32_0","argument":"福沢諭吉は、貧困層に高等教育が不要だとする考えに対して、智力が成長しても実地に活かせる地位や財産がなければ不満が溜まり、社会の安寧を脅かす原因が増えると警告している。","comment_id":"32","x":17.012737,"y":7.632336,"p":0},{"arg_id":"A34_0","argument":"立地が良いと志望度が上がる。","comment_id":"34","x":16.466352,"y":7.8678412,"p":0.3830008760508696},{"arg_id":"A34_1","argument":"綺麗なキャンパスが志望度を上げる。","comment_id":"34","x":16.169704,"y":8.477692,"p":1},{"arg_id":"A34_2","argument":"キャンパスライフを送ることに意味がある。","comment_id":"34","x":16.2396,"y":8.581822,"p":1},{"arg_id":"A44_0","argument":"女性は意思決定に無意識に参加できないという刷り込みから解放されるべきである","comment_id":"44","x":16.362377,"y":6.440936,"p":0},{"arg_id":"A48_0","argument":"最新の知識を体得して社会に出るべきである。","comment_id":"48","x":16.758217,"y":6.532269,"p":0},{"arg_id":"A56_0","argument":"どんな専門であろうが、それは入り口でしかなく、最終的には自分自身の存在について考えることに行き着く。","comment_id":"56","x":16.812119,"y":8.287939,"p":1},{"arg_id":"A59_0","argument":"どんな専門であろうが、それは入り口でしかなく、最終的には自分自身の存在について考えることに行き着く。","comment_id":"59","x":16.839407,"y":8.266059,"p":1},{"arg_id":"A81_0","argument":"大学2年生からインターンを始めたのは、就職への焦りからであった。","comment_id":"81","x":16.893085,"y":8.707751,"p":0},{"arg_id":"A81_2","argument":"心の貧しさと経済的な貧しさを感じていた。","comment_id":"81","x":16.578773,"y":7.699035,"p":0.4998670857582736},{"arg_id":"A81_3","argument":"社会に対する漠然とした危機感があった。","comment_id":"81","x":16.10071,"y":7.3067517,"p":1},{"arg_id":"A81_4","argument":"切り詰めなければならず、のんびりしていてはいけないという思いがあった。","comment_id":"81","x":16.407343,"y":6.881635,"p":0.3622283853912321},{"arg_id":"A83_0","argument":"国公立に行きたい人は浪人できない恐怖を抱えており、切羽詰まっている。","comment_id":"83","x":16.24124,"y":7.3365345,"p":1},{"arg_id":"A83_1","argument":"体育会系の思考が強まり、受かるか受からないかしか見れない状況になる。","comment_id":"83","x":16.837648,"y":8.186988,"p":1},{"arg_id":"A84_0","argument":"キャンパスは、同僚の娘（5歳）の散歩ルートとして利用されることがある。","comment_id":"84","x":16.07754,"y":8.492798,"p":0.6782690514132014},{"arg_id":"A87_2","argument":"特定の人や土地への依存度が低いと感じている。","comment_id":"87","x":16.36256,"y":7.473715,"p":0.7186115803632568},{"arg_id":"A91_1","argument":"キャンパスライフが大事で、就職先に対する強い期待は持っていなかった。","comment_id":"91","x":16.353281,"y":8.631363,"p":0.5238519765974293},{"arg_id":"A91_2","argument":"社会人になってから高い給料の会社を望むようになった。","comment_id":"91","x":17.4708,"y":7.5813165,"p":0},{"arg_id":"A94_0","argument":"社会に出てから出会ったことのない、霞を食べて生きているような人がいた。","comment_id":"94","x":16.255262,"y":7.2848444,"p":1},{"arg_id":"A97_2","argument":"大人になってから学びたいことを学べる場があれば幸福度が上がる可能性がある。","comment_id":"97","x":17.33635,"y":8.391761,"p":0.9291444320448018},{"arg_id":"A99_0","argument":"ナイトワーカーは大学に行きたかったが、昼間のキャンパスライフに参加することに抵抗を感じている。","comment_id":"99","x":16.612137,"y":8.781039,"p":0.4194228919586424}]},{"cluster":"大学の役割の歴史的変遷と未来の展望","cluster_id":"0","takeaways":"地方私立大学、特に女子大学や短期大学、文系学部の統廃合が進む中、歴史的には大学の役割が変化してきた。14世紀から16世紀にかけて大学は増加したが、資格授与機関としての機能が強まり、知識の形骸化が進行。宗教改革によって大学間の断絶が生じ、知のネットワークが形成されにくくなり、中世的な大学システムは機能不全に陥った。\n\nまた、16世紀から18世紀にかけての印刷技術の発展により、知識の普及が加速し、在野の著述家が最先端の知を生み出すようになった。この時期、知識を求めるための旅は不可欠であり、知識人との対話や修道院の写本が重要な役割を果たしていた。1990年代後半以降、知識基盤社会への移行に伴い、大学の教育・研究機能に対する期待が高まっている。","arguments":[{"arg_id":"A47_0","argument":"地方私大、特に女子大、短大、文系学部の統廃合が進んでいる。","comment_id":"47","x":20.313194,"y":7.1952786,"p":0},{"arg_id":"A61_0","argument":"14世紀から16世紀にかけて大学の数が増加し、単なる資格授与機関として知の形骸化が進んだ。","comment_id":"61","x":20.654259,"y":7.422154,"p":1},{"arg_id":"A61_1","argument":"宗教改革により、宗派ごとに大学に断絶が生じ、国家形成が進む中でヨーロッパを横断する知のネットワークが作られにくくなった。","comment_id":"61","x":20.904577,"y":7.14763,"p":0.7688342506726568},{"arg_id":"A61_2","argument":"中世的な大学システムは機能不全に陥った。","comment_id":"61","x":20.507711,"y":7.3229494,"p":1},{"arg_id":"A62_0","argument":"科学革命において、コペルニクスの地動説が提唱されたが、同時代には重大な天文学的発見はなかった。天文学者は本格的に印刷された数表を利用し、データの比較照合による仮説検証を行った。","comment_id":"62","x":20.93692,"y":6.6011477,"p":1},{"arg_id":"A62_1","argument":"宗教改革では、教会堂と印刷本の闘いがあり、マルティン・ルターは豊富な出版の経験を活かして印刷を教会批判に縦横に活用した。","comment_id":"62","x":20.650053,"y":6.9178805,"p":1},{"arg_id":"A63_0","argument":"16世紀から18世紀にかけて、グーテンベルクの活版印刷により本が普及し、最先端の知を生み出す知識人は大学の研究者ではなく、在野の著述家であった。","comment_id":"63","x":20.890667,"y":6.73874,"p":1},{"arg_id":"A64_0","argument":"本の生産量の劇的増加は知識の大量複製・普及をもたらし、情報爆発を引き起こす。","comment_id":"64","x":20.541473,"y":6.175466,"p":0},{"arg_id":"A64_1","argument":"知識を求めての放浪の時代が終わり、中世的大学システムの基盤が喪失する。","comment_id":"64","x":20.796669,"y":7.1149035,"p":1},{"arg_id":"A64_2","argument":"多数の本を集めての比較照合の時代が始まる。","comment_id":"64","x":20.94978,"y":6.5239778,"p":1},{"arg_id":"A65_0","argument":"出版技術が発展するまでは、知識を求める際、知識人に会いに行くか修道院の写本を読む必要があったため、学びと旅は不可分な存在である。","comment_id":"65","x":21.104546,"y":6.753053,"p":1},{"arg_id":"A69_0","argument":"1990年代後半以降、知識基盤社会への移行により大学の教育・研究機能に対する社会の期待が大きくなった。","comment_id":"69","x":20.588171,"y":7.5312567,"p":1},{"arg_id":"A90_2","argument":"神学にはロマンチックな要素があり、キャリアチェンジもロマンを求めた結果である。","comment_id":"90","x":20.760384,"y":6.862596,"p":1}]}],"comments":{"0":{"comment":"シーズの発掘から成果の活用まで一貫して管理する体制がない"},"1":{"comment":"大学発ベンチャーを製薬企業が買収。自社の一研究部門にする"},"2":{"comment":"経済的なコミュニティを形成"},"3":{"comment":"自社の研究施設を持つことも可能\n例）GAFA、NTT、野村総研"},"4":{"comment":"大学の近くに企業や投資家が集まる"},"5":{"comment":"特許等の研究成果を企業が独占できない。独占したら莫大な実施料の支払い義務を負う。"},"6":{"comment":"留学生を受け入れて海外企業とのつながりを創出"},"7":{"comment":"国立大学も含めてが自前で研究費の調達が必要。企業からの寄付講座などが無いと研究の存続が厳しい。\n→民間からお金が降りやすい研究テーマだけ継続。\n→実学偏重"},"8":{"comment":"学内or大学の近くに大学発ベンチャー"},"9":{"comment":"共同研究しても権利関係で揉める。\n例：小野薬品 vs 本庶佑氏\nオプジーボ訴訟"},"10":{"comment":"産学連携は研究費になっても大学の運営費にならない。"},"11":{"comment":"実用化に繋がりそうな技術シーズの情報発信が少なく、企業がキャッチアップしづらい。"},"12":{"comment":"技術指導・共同研究契約の手続きが煩雑"},"13":{"comment":"営業秘密や利益造反行為など共同研究・委託研究に関するルール・マネジメントが不十分"},"14":{"comment":"映画：「あのこは貴族」\n→学力で難関大学に入れても、教養面や生活面で差を感じる機会が多い（友人同士の遊び方、キャリア・結婚観、アートへの造詣の深さなど）。とはいえ、裕福な層が楽をしているわけでもない。政治家の息子は政治家、貴方の結婚相手はこのくらいの格がないと、というように、将来の選択肢がなかったり、親の期待値の高さに押しつぶされかねない。生育環境が人生のしがらみとなって現れる。"},"15":{"comment":"人間は社会性の生き物。他者からの眼差しで自分のありようを決めてしまい、不自由を感じることがある。\ncf: サルトル「地獄とは他人のことだ」"},"16":{"comment":"諸外国の大学院は授業料を支払うどころか、院生に給料が出るのが普通。"},"17":{"comment":"大学・大学院での経済支援が不透明であり、相当時間アルバイトに費やさざるを得ない学生に向けたカリキュラムにはなっていない。"},"18":{"comment":"教育格差\n親が大卒だと子も大卒になりやすい。\n・就職のしやすさなど、大卒のメリットがわかっている。\n・習い事を子供にさせている（子供が自発的にやりたいように仕向ける＝意図的養育（交渉のすすめ）↔︎放任的養育（親が子に命令し、交渉は望まない））。\n・そもそも非大卒者に比べて年収が高いことが多いため、子にとって大学進学への金銭的心理的ハードルが低い。"},"19":{"comment":"周囲（特に家族）に敬意を払われない状態で努力を続けて、かつ運も良くないと進学できない。"},"20":{"comment":"成績連動型奨学金だと絶対に成績を落とせないというプレッシャーが常にのしかかる。"},"21":{"comment":"大学の学費自体を値上げする\nBy慶應義塾長"},"22":{"comment":"多様な関わり方の余白を広げていくこと"},"23":{"comment":"コモニング：\n気ままに参加をし、それを受入れあい、管理する。関係性的であり実践的。"},"24":{"comment":"DAO\n→プロトコルが中心にあり、それに基づいて人々の行動が調整されている、そのエコシステム。PJに参加し、トークンを得る。"},"25":{"comment":"人間の直接的な介入なしに、定められたルールに基づいて行動。参加者の綿密なコミュニケーションや相互理解は不要"},"26":{"comment":"大学＝コモンズ空間：誰かに所有された空間ではないと思い、行動し合うこと、交渉し合うことで形作られた空間"},"27":{"comment":"人々がそれを私たちのコモンズだと思うこと、あるいはそう思って行動しあうこと、交渉しあうことで形作られる"},"28":{"comment":"Web3（自律分散型）\n→ユーザーからステークホルダーへ。"},"29":{"comment":"図書館や食堂は一般利用可能"},"30":{"comment":"寮をクリエイターコミュニティとして貸出希望"},"31":{"comment":"法哲学の講義：二人でオレンジを取り合い。\n→法律はオレンジの所有権者を決めることはできても、需要に応じて皮（マーマレード作りたい）と果肉（果肉食べたい）に分けたらいいという解決策は出せない\n→法律だけ学んでいても社会では通用しない。"},"32":{"comment":"福沢諭吉\n貧困層には高等教育不要？→「智力」が成長しても、実地に活かせる地位や財産がなければ不満が溜まり「社会の安寧」を脅かす原因が増える"},"33":{"comment":"オンラインのつながりは便利で効率的な一方、人間関係が出来上がった人や意見を同じくする人同士で集まりがち？"},"34":{"comment":"立地が良かったり、綺麗なキャンパスがあると、志望度が上がる。キャンパスライフを送ることに意味がある。"},"35":{"comment":"就職後の階層関係を意識して良い大学を選ぶ"},"36":{"comment":"労働時間でカウントすると個人差がある。"},"37":{"comment":"学生と教師が結びつき、学生は教養と研究、教師は研究と教育を行う＋事務職は、金策を練ったり、大学としてのブランディングを実施。"},"38":{"comment":"大学教員がロールモデルになるには？\n→知的にかっこよくないとだめ\n→特権的な時間の自由を世間の常識とは違う価値観で使う。\n→クリエイティブな価値観を見せる＝博覧強記のかっこよさ"},"39":{"comment":"研究者の魅力は？\n→世間や時代に合わせずに世間に顧みられずとも、自己本位を貫くところ（↔︎他人本位な労働者）。趣味的な職業人でいる点。"},"40":{"comment":"国が大学セクターを動かすために、補助金をばら撒く→補助金申請につられると、研究・教育時間を削って、省庁の文書を読み込み、申請プレゼンなどの作業に時間を費やす\n→若手研究者は疲弊。"},"41":{"comment":"専門業務型裁量労働者？"},"42":{"comment":"社会人キャリアのある人を教授として招聘"},"43":{"comment":"①教育、②研究、③社会（地域・経済・国際）貢献"},"44":{"comment":"「常識」をアンロックする。女性は意思決定に無意識に参加できないという刷り込みから解放\ncf 椙山女学園"},"45":{"comment":"地方大学は、当該地方に新たな若者（働き手）を供給している"},"46":{"comment":"学生に目標を決めずに迷う時間を与える"},"47":{"comment":"地方私大（特に女子大、短大、文系学部飲みの大学）の統廃合"},"48":{"comment":"最新の知識を体得して社会に出る"},"49":{"comment":"労働：生命を維持するために実施\n単一性・私的"},"50":{"comment":"社会人は「時間当たり採算」"},"51":{"comment":"限られた時間で成果を出す事が求められる"},"52":{"comment":"リカレント教育"},"53":{"comment":"活動：他者との共同行為、特に言葉を用いたコミュニケーション\n複数性・公共性"},"54":{"comment":"大学は、生活の心配をせずにその問いを持つことができ、果ての果てまで考え、対話するところ。"},"55":{"comment":"大学の使命は、文理融合を進めること。専門分野を複数持つ方がそれぞれの分野に役にたつ。\ncf: 数学者 岡潔「数学の中心は情緒」数学×文学など"},"56":{"comment":"どんな専門であろうがそれは入り口でしかなく、最終的に行き着くところは、自分自身の存在について考えること"},"57":{"comment":"実学から離れたところで、好奇心の赴くまま好きなことを学ぶ"},"58":{"comment":"公共的な問題について話し合い、複数的な意見を交換する共創空間が必要"},"59":{"comment":"どんな専門であろうがそれは入り口でしかなく、最終的に行き着くところは、自分自身の存在について考えること"},"60":{"comment":"様々な国、文化を持つ人々の知の共有と交流"},"61":{"comment":"14世紀から16世紀、大学の数が増加。単なる資格授与機関へ（知の形骸化）\n→宗教改革で宗派ごとに大学に断絶が起きる。\n国家形成でヨーロッパを横断する知のネットワークが作られにくくなる。\n→中世的な大学システムの機能不全。"},"62":{"comment":"科学革命\n(コペルニクスの地動説⇔同時代に重大な天文学的発見はない) 天文学者が本格的に印刷された数表等を利用⇒データの比較照合による仮説検証\n\n宗教改革\n教会堂と印刷本の闘い マルティン・ルター=豊富な出版の経験→印刷を教会批判に縦横に活用"},"63":{"comment":"16世紀から18世紀にかけて、グーテンベルクの活版印刷→本が普及→最先端の知を生み出す知識人は、大学の研究者ではなく、在野の著述家（出版を通じたネットワーク）"},"64":{"comment":"本の生産量の劇的増加=知識の大量複製・普及(情報爆発) ⇒知識を求めての放浪の時代の終わり=中世的大学システムの基盤の喪失 ⇒多数の本を集めての比較照合の時代の始まり"},"65":{"comment":"出版技術が発展するまでは、知識を求める際、その知識をもつ知識人に会いに行く or 修道院などに収蔵されている写本を読む\n→「学び」と「旅」は不可分な存在"},"66":{"comment":"近代の大学：学生・教師の協同組合(\"universitas\"自由な移動)⇔ 都市支配層"},"67":{"comment":"教会や広場などの都市施設を利用して授業実施→この集団が都市から都市へと渡り歩く→次々と新たな大学が都市の中に生み出される"},"68":{"comment":"ミネルヴァ大学\n2012年にアメリカで設立。\n・伝統的なキャンパスを持たない。\n・学生は世界各地を移動しながら学ぶ。\n→学問的なカリキュラム（オンライン）と異文化体験（寮が世界各国にある）を融合させた教育の提供。"},"69":{"comment":"1990年代後半以降、知識基盤社会への移行等により大学の教育・研究機能に対する社会の期待が極めて大きくなった。\nBUT大学教育は18歳人口の急激な減少に伴う大衆化(進学率の急激な上昇)や高等学校教育の多様化等により高等教育の質の確保が大きな課題"},"70":{"comment":"大卒であることではなく「どこの大学を出ているのか」で就職先が決まる"},"71":{"comment":"18歳人口の6割が大学+短大に進学\n※一部のエリートのためのものではない"},"72":{"comment":"大学は自国の文化復興のための国民国家の基盤と再定義"},"73":{"comment":"「フンボルト的大学観」：研究と教育を一体として結合させる。大学人を第一義的に研究者であると規定し、研究成果の披瀝が最高の教育であるとする考え方"},"74":{"comment":"文系におけるゼミナール（議論）、理系における実験室（観察と実験）の確立\n→学生と教師が共に学ぶ。"},"75":{"comment":"日本の大学設立の目的は国力強化（近代化の装置）\n→日本の国益に直結するエリート養成学校的"},"76":{"comment":"1930年代スペイン\nオルテガ：大学の使命は、1.教養教育2.専門職業人養成3.科学"},"77":{"comment":"２０世紀　アメリカ\nクラーク・カー『大学の効用』：現代の大学は教育・研究・奉仕の多機能を持った「マルチバーシティ」"},"78":{"comment":"PBL型教育"},"79":{"comment":"偏差値重視の受験内容ではなく、新しい入試の基準も必要かも"},"80":{"comment":"メーカーは量産化から販売までリスクを負う一方で、研究はリスクが少ないように映る。"},"81":{"comment":"就職で焦ってたから大学2年生からインターン\n・行動が打算だった=履歴書に書くため\n・心が貧しい、財布も貧しい\n・社会にお金ないですっていう漠然とした危機感\n・切り詰めなきゃ、のんびりしてちゃダメだ"},"82":{"comment":"給付型奨学金も振込先によっては両親から使い込まれる。結果、バイト三昧になる"},"83":{"comment":"国公立に行きたい人は、浪人できない恐怖。切羽詰まっている。\n→体育会系で脳筋になる。受かるか受からないかしか見れない。"},"84":{"comment":"キャンパスは、同僚の娘（５歳）の散歩ルート"},"85":{"comment":"図書館の開架図書コーナーには地域のおじいちゃんがいた"},"86":{"comment":"大内さんの話\n同級生は恋バナ、推しのアイドル、MBTIの話をしてる。"},"87":{"comment":"大内さんの話\nコロナ下で入学。同一の目的（Web３に関心のある仲間など）で集うオンラインの仲間との間の方が交流が活発。ただ、主張はやや一方的かも。\n→直接会うことがない分、教授・同級生と仲良くなりにくかった。\n→特定のヒト・土地への依存度が低そう。"},"88":{"comment":"T教授・岡村さん（元准教授）\nコロナ下でオンラインゼミを開講した。思ったよりも闊達な議論が可能。顔色を窺わない分、発言することへの心理的安全性が上がったかも。一方、相手を見ているようで、自分の話をしているというコミュニケーションになっている。気を遣うのが難しいのかも。"},"89":{"comment":"義妹（大４）\n大学の学部は就職に役立ちそうなとこで選んだ。外大やったら空港で働けそうやし。哲学とかは就職と結びつきにくい。遠い感じ。"},"90":{"comment":"夫（機械・電子・電気系）が学生時代一番印象に残った授業は「山陰の歴史」「宗教と死生観」\n→わけわからん感じが良かった。工学と比べると異質すぎて。レポートに私見を入れる（工学系のレポートに私見はない）。\n→神学はロマンチックなところがあった。自分の人生の中で、キャリアチェンジしたのもロマンを求めたから。"},"91":{"comment":"夫の話\n大学には「余白」を楽しみに行った。キャンパスライフが大事で、いい就職先に行きたい感覚はゼロ。社会人になってからの方が高い給料の会社がいいな〜とか思うようになった。"},"92":{"comment":"一般教養科目で、色んな学部学科の人と交わる分、授業は1年目が一番楽しかった。"},"93":{"comment":"研究室のドアを外して暖簾に変更"},"94":{"comment":"社会に出てから出会ったことのない、霞食べて生きてそうな人がいた。"},"95":{"comment":"T教授\n論文めっちゃ書いてるし研究者として一流だろ、副学長もやったし事務できるだろ。その上お前、ゼミ生毎年３０人（※この数字は盛ってる）は出してるんだから、めちゃくちゃ優秀なんだよ、俺。\n→研究、管理、教育の三役をこなすのは至難の業。"},"96":{"comment":"岡村さんの話\n研究と教育、管理と教育とか二つならできる人いるんだよ。僕もゼミと研究は楽しかったよ。でも書類仕事多すぎるし断れへんしで、大学辞めて民間の研究所に行ってん。研究だけやってたら良くてリサーチ予算１０倍やで。"},"97":{"comment":"華道の先生（83）の話\n→シングルマザーで二人育てるんはしんどかったですよ。でも私は華道があったから疲れ切らなかった。華道を始めたのは働き始めてから。仕事から帰ったら子供しかないみたいにならなくて良かった。華道なんて役に立つもんじゃないけど、私は「無駄」に救われた。\n→大人になってから学びたいこと（教養）を学べる場があれば幸福度も上がる？"},"98":{"comment":"私の大学院卒業代のトップは社会人学生(自衛官)"},"99":{"comment":"ナイトワーカーの友人の話\n→大学行ってみたかったよ。今でも哲学とか宗教系とかいいなーって思う。お金的に行けなくはないのよ。でも自分が１８歳の子達と昼間にキャンパスライフするのは、痒くて無理。"},"100":{"comment":"義妹（大４）の話\n・外大は在学中の海外留学が当たり前（地元高校にいた頃には想像できない文化）。\n・上記に感化されて留学すると、語学力の向上以上に、実地で異文化に触れる驚き・喜びを知った（それぞれの土地の文化や特産品の魅力を広めていきたい）。\n→大学は、学生にとって新たな選択肢をくれるところ"},"101":{"comment":"研究科に入ると先生や先輩後輩との距離が近い。同じ学問を追求する仲間ができる"}},"overview":"現在の大学は、産学連携の進化や実務教育の強化が求められる一方で、研究資金の調達や教育の質確保に苦しんでいます。特に、AIの活用やコミュニティ形成が重要視され、大学は地域社会との連携を強化し、多機能性を持つ「マルチバーシティ」としての役割を果たす必要があります。国際的な連携やキャリア支援の強化も不可欠であり、実学重視と学問の多様性の調和が求められています。将来的には、教育の質向上と社会的期待に応えるため、大学は柔軟な教育モデルを採用し、個人の成長を促進する環境を整えることが重要です。","config":{"name":"大内裕未 KJ法","question":"大学の役割はどのように変化したのか、そして、大学の未来はどうなっていくのか?","input":"KJ法","model":"gpt-4o-mini","extraction":{"workers":3,"limit":103,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []","prompt":"/system\n\nあなたはプロのリサーチアシスタントであり、私の仕事は論拠のきれいなデータセットを準備することです。\n\n背景として、私は大学に関するさまざまなメディアソースやインタビューからコメントを集めています。私は、大学に関する主な考えや傾向を特定するお手伝いをしていただきたいのです。あなたの仕事は、これらのコメントを分析し、データから浮かび上がる主なテーマや傾向を明確かつ簡潔に要約することです。要約は読みやすく洞察力に富んだものになるよう重点的に取り組み、繰り返されるパターンや重要な洞察を強調してください。\n本当に必要な場合のみ、2つの別々の主張に分けることもできますが、多くの場合、1つの主張に戻すのが最善でしょう。\n\n結果は、きちんとフォーマットされた文字列形式（strings）のJSONリストとして返してください。\nすべての応答は必ずダブルクォーテーション (\") で囲まれた正確なJSONリスト形式で返してください。\n\n/human\n\nAI技術は、そのライフサイクル全体を通じて、自らの環境への影響を低減することに重点を置いて開発されるべきである。\n\n/ai\n\n[\n\"AI技術の環境への影響を低減することに重点を置くべきである\"\n]\n\n/human\n\nAIの能力、限界、倫理的考察について、一般市民に教育を行うための協調的な取り組みを行うべきである。\n\n/ai\n\n[\n\"AIの能力について、一般市民に教育を行うべきである\",\n\"AIの限界と倫理的考察について、一般市民に教育を行うべきである\"\n]\n\n/human\n\nAIは、エネルギー効率と居住者の健康のために、スマートホームやスマートビルを最適化することができる。\n\n/ai \n\n[\n\"AIはスマートホームやスマートビルをエネルギー効率と居住者の健康のために最適化できる。\"\n]\n\n/human \n\nAIはエネルギー網の最適化を支援し、無駄と二酸化炭素排出量を削減できる。\n\n/ai \n\n[\n\"AIはエネルギー網を最適化し、無駄と二酸化炭素排出量を削減できる。\"\n]","model":"gpt-4o-mini"},"clustering":{"clusters":8,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # 必要なモジュールのインポート\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdの辞書パスを指定\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # 品詞フィルタリングを行うトークナイザー\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # 名詞、動詞、形容詞だけを抽出する\n            if node.feature.startswith('名詞') or node.feature.startswith('動詞') or node.feature.startswith('形容詞'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # 日本語のストップワードリストを作成（必要に応じて拡張可能）\n    japanese_stopwords = [\"これ\", \"それ\", \"あれ\", \"こと\", \"もの\", \"ため\", \"よう\", \"さん\", \"する\", \"なる\", \"ある\", \"いる\"]\n\n    # 日本語トークナイザーとストップワードを使用する\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # トピックモデルのフィッティング\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"},"intro":"このレポートは、吉江美月さんのリサーチデータを元にAIによって生成されました。","output_dir":"KJ法","previous":{"name":"大内裕未 KJ法","question":"大学の役割はどのように変化したのか、そして、大学の未来はどうなっていくのか?","input":"KJ法","model":"gpt-4o-mini","extraction":{"workers":3,"limit":103,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []","prompt":"/system\n\nあなたはプロのリサーチアシスタントであり、私の仕事は論拠のきれいなデータセットを準備することです。\n\n背景として、私は大学に関するさまざまなメディアソースやインタビューからコメントを集めています。私は、大学に関する主な考えや傾向を特定するお手伝いをしていただきたいのです。あなたの仕事は、これらのコメントを分析し、データから浮かび上がる主なテーマや傾向を明確かつ簡潔に要約することです。要約は読みやすく洞察力に富んだものになるよう重点的に取り組み、繰り返されるパターンや重要な洞察を強調してください。\n本当に必要な場合のみ、2つの別々の主張に分けることもできますが、多くの場合、1つの主張に戻すのが最善でしょう。\n\n結果は、きちんとフォーマットされた文字列形式（strings）のJSONリストとして返してください。\nすべての応答は必ずダブルクォーテーション (\") で囲まれた正確なJSONリスト形式で返してください。\n\n/human\n\nAI技術は、そのライフサイクル全体を通じて、自らの環境への影響を低減することに重点を置いて開発されるべきである。\n\n/ai\n\n[\n\"AI技術の環境への影響を低減することに重点を置くべきである\"\n]\n\n/human\n\nAIの能力、限界、倫理的考察について、一般市民に教育を行うための協調的な取り組みを行うべきである。\n\n/ai\n\n[\n\"AIの能力について、一般市民に教育を行うべきである\",\n\"AIの限界と倫理的考察について、一般市民に教育を行うべきである\"\n]\n\n/human\n\nAIは、エネルギー効率と居住者の健康のために、スマートホームやスマートビルを最適化することができる。\n\n/ai \n\n[\n\"AIはスマートホームやスマートビルをエネルギー効率と居住者の健康のために最適化できる。\"\n]\n\n/human \n\nAIはエネルギー網の最適化を支援し、無駄と二酸化炭素排出量を削減できる。\n\n/ai \n\n[\n\"AIはエネルギー網を最適化し、無駄と二酸化炭素排出量を削減できる。\"\n]","model":"gpt-4o-mini"},"clustering":{"clusters":8,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # 必要なモジュールのインポート\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdの辞書パスを指定\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # 品詞フィルタリングを行うトークナイザー\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # 名詞、動詞、形容詞だけを抽出する\n            if node.feature.startswith('名詞') or node.feature.startswith('動詞') or node.feature.startswith('形容詞'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # 日本語のストップワードリストを作成（必要に応じて拡張可能）\n    japanese_stopwords = [\"これ\", \"それ\", \"あれ\", \"こと\", \"もの\", \"ため\", \"よう\", \"さん\", \"する\", \"なる\", \"ある\", \"いる\"]\n\n    # 日本語トークナイザーとストップワードを使用する\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # トピックモデルのフィッティング\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"},"intro":"このレポートは、吉江美月さんのリサーチデータを元にAIによって生成されました。","output_dir":"KJ法","embedding":{"source_code":"\nfrom langchain_community.embeddings import OpenAIEmbeddings\nfrom langchain_community.chat_models import ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nあなたは、大学の役割や未来に関する広範なコンサルテーション内の一連の議論に対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。あなたには、相談の主な質問、クラスター内の議論のリスト、およびこのクラスター外の議論のリストが与えられます。あなたはクラスターを最もよく要約する1つの具体的で独自のカテゴリーラベルを回答します。\n\n質問からすでに明らかな文脈は含めないでください（例えば、相談の質問が「大学の未来における役割の変化とは何か」のようなものであれば、クラスターのラベルに「大学の未来における」と繰り返す必要はありません）。\n\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さと具体性が必要です。以下のキーワードや視点（例えば、「多機能化」「地域社会への貢献」「社会的役割」「コミュニティ形成」「変革と課題」「デジタルトランスフォーメーション」「キャリア教育」など）を考慮し、クラスターを最もよく要約するラベルを作成してください。\n\n重要：ラベルは独自性があり、クラスター内部の議論の焦点やテーマに沿った具体的なキーワードを用いてください。\n\n/human\n\nコンサルテーションの質問: 「大学の未来における役割の変化とその影響は何だと思いますか？」\n\n関心のあるクラスター以外の論点の例\n\n * 地方大学と都市大学の教育格差の拡大。\n * オンライン教育の普及によるキャンパスの存在意義の変化。\n * 大学と企業の連携が進むことで、新しい研究開発モデルの登場。\n * 学費の高騰と教育機会の公平性に関する議論。\n * 国際的な大学ランキングにおける日本の大学の位置づけと評価。\n * 大学の持続可能性に対する社会的責任の強化。\n * 学生の価値観の変化による学問の選択傾向の変化。\n\nクラスター内部での議論の例\n\n * 大学の地域貢献が地元の経済や社会活動に大きな影響を与えている。\n * 学生のキャリア意識の高まりに伴い、大学での実務教育が重要視されている。\n * 研究開発とイノベーションの促進が、大学と地域社会の連携を強化している。\n * 海外の大学との連携を通じた国際的な学術交流が進んでいる。\n * 学生の多様性が増加する中で、大学教育のあり方が見直されている。\n * 大学の運営におけるデジタルトランスフォーメーションの必要性が高まっている。\n * 環境問題への取り組みが大学の使命に組み込まれつつある。\n\n/ai \n\n大学の多機能化と地域社会への貢献","model":"gpt-4o-mini"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nあなたはシンクタンクで働くリサーチアシスタントのエキスパートです。さまざまなメディアソースや大学に関するインタビューのコメントのリストが渡されます。あなたは、主な要点を1~2段落にまとめて回答します。あなたは簡潔で読みやすい短い文章を書くことができます。 \n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o-mini"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。あなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。あなたの仕事は、その結果を簡潔にまとめることです。あなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。\nさらに、分析しているデータに基づいて、大学の将来に関する洞察を提供してください。高等教育の将来を形作る可能性のある新たな傾向、課題、機会を強調してください。分析では、進化する大学の状況に関連する、明確な将来展望を示す必要があります。","model":"gpt-4o-mini"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) > 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":false,"reason":"nothing changed"},{"step":"embedding","run":false,"reason":"nothing changed"},{"step":"clustering","run":false,"reason":"nothing changed"},{"step":"labelling","run":true,"reason":"some parameters changed: prompt"},{"step":"takeaways","run":false,"reason":"nothing changed"},{"step":"overview","run":true,"reason":"some dependent steps will re-run: labelling"},{"step":"aggregation","run":true,"reason":"some dependent steps will re-run: labelling, overview"},{"step":"visualization","run":true,"reason":"some dependent steps will re-run: aggregation"}],"status":"completed","start_time":"2024-09-24T18:46:06.524788","completed_jobs":[{"step":"labelling","completed":"2024-09-24T18:46:14.730657","duration":8.20168,"params":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nあなたは、大学の役割や未来に関する広範なコンサルテーション内の一連の議論に対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。あなたには、相談の主な質問、クラスター内の議論のリスト、およびこのクラスター外の議論のリストが与えられます。あなたはクラスターを最もよく要約する1つの具体的で独自のカテゴリーラベルを回答します。\n\n質問からすでに明らかな文脈は含めないでください（例えば、相談の質問が「大学の未来における役割の変化とは何か」のようなものであれば、クラスターのラベルに「大学の未来における」と繰り返す必要はありません）。\n\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さと具体性が必要です。以下のキーワードや視点（例えば、「多機能化」「地域社会への貢献」「社会的役割」「コミュニティ形成」「変革と課題」「デジタルトランスフォーメーション」「キャリア教育」など）を考慮し、クラスターを最もよく要約するラベルを作成してください。\n\n重要：ラベルは独自性があり、クラスター内部の議論の焦点やテーマに沿った具体的なキーワードを用いてください。\n\n/human\n\nコンサルテーションの質問: 「大学の未来における役割の変化とその影響は何だと思いますか？」\n\n関心のあるクラスター以外の論点の例\n\n * 地方大学と都市大学の教育格差の拡大。\n * オンライン教育の普及によるキャンパスの存在意義の変化。\n * 大学と企業の連携が進むことで、新しい研究開発モデルの登場。\n * 学費の高騰と教育機会の公平性に関する議論。\n * 国際的な大学ランキングにおける日本の大学の位置づけと評価。\n * 大学の持続可能性に対する社会的責任の強化。\n * 学生の価値観の変化による学問の選択傾向の変化。\n\nクラスター内部での議論の例\n\n * 大学の地域貢献が地元の経済や社会活動に大きな影響を与えている。\n * 学生のキャリア意識の高まりに伴い、大学での実務教育が重要視されている。\n * 研究開発とイノベーションの促進が、大学と地域社会の連携を強化している。\n * 海外の大学との連携を通じた国際的な学術交流が進んでいる。\n * 学生の多様性が増加する中で、大学教育のあり方が見直されている。\n * 大学の運営におけるデジタルトランスフォーメーションの必要性が高まっている。\n * 環境問題への取り組みが大学の使命に組み込まれつつある。\n\n/ai \n\n大学の多機能化と地域社会への貢献","model":"gpt-4o-mini"}},{"step":"overview","completed":"2024-09-24T18:46:17.691385","duration":2.958032,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。あなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。あなたの仕事は、その結果を簡潔にまとめることです。あなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。\nさらに、分析しているデータに基づいて、大学の将来に関する洞察を提供してください。高等教育の将来を形作る可能性のある新たな傾向、課題、機会を強調してください。分析では、進化する大学の状況に関連する、明確な将来展望を示す必要があります。","model":"gpt-4o-mini"}},{"step":"aggregation","completed":"2024-09-24T18:46:17.784395","duration":0.090002,"params":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) > 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"}},{"step":"visualization","completed":"2024-09-24T18:46:39.765126","duration":21.979631,"params":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"}}],"lock_until":"2024-09-24T18:51:39.767093","current_job":"visualization","current_job_started":"2024-09-24T18:46:17.785530","current_job_progress":null,"current_jop_tasks":null,"previously_completed_jobs":[{"step":"takeaways","completed":"2024-09-24T18:41:13.565147","duration":25.994279,"params":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nあなたはシンクタンクで働くリサーチアシスタントのエキスパートです。さまざまなメディアソースや大学に関するインタビューのコメントのリストが渡されます。あなたは、主な要点を1~2段落にまとめて回答します。あなたは簡潔で読みやすい短い文章を書くことができます。 \n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o-mini"}},{"step":"extraction","completed":"2024-09-24T18:38:49.094860","duration":46.805186,"params":{"workers":3,"limit":103,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []","prompt":"/system\n\nあなたはプロのリサーチアシスタントであり、私の仕事は論拠のきれいなデータセットを準備することです。\n\n背景として、私は大学に関するさまざまなメディアソースやインタビューからコメントを集めています。私は、大学に関する主な考えや傾向を特定するお手伝いをしていただきたいのです。あなたの仕事は、これらのコメントを分析し、データから浮かび上がる主なテーマや傾向を明確かつ簡潔に要約することです。要約は読みやすく洞察力に富んだものになるよう重点的に取り組み、繰り返されるパターンや重要な洞察を強調してください。\n本当に必要な場合のみ、2つの別々の主張に分けることもできますが、多くの場合、1つの主張に戻すのが最善でしょう。\n\n結果は、きちんとフォーマットされた文字列形式（strings）のJSONリストとして返してください。\nすべての応答は必ずダブルクォーテーション (\") で囲まれた正確なJSONリスト形式で返してください。\n\n/human\n\nAI技術は、そのライフサイクル全体を通じて、自らの環境への影響を低減することに重点を置いて開発されるべきである。\n\n/ai\n\n[\n\"AI技術の環境への影響を低減することに重点を置くべきである\"\n]\n\n/human\n\nAIの能力、限界、倫理的考察について、一般市民に教育を行うための協調的な取り組みを行うべきである。\n\n/ai\n\n[\n\"AIの能力について、一般市民に教育を行うべきである\",\n\"AIの限界と倫理的考察について、一般市民に教育を行うべきである\"\n]\n\n/human\n\nAIは、エネルギー効率と居住者の健康のために、スマートホームやスマートビルを最適化することができる。\n\n/ai \n\n[\n\"AIはスマートホームやスマートビルをエネルギー効率と居住者の健康のために最適化できる。\"\n]\n\n/human \n\nAIはエネルギー網の最適化を支援し、無駄と二酸化炭素排出量を削減できる。\n\n/ai \n\n[\n\"AIはエネルギー網を最適化し、無駄と二酸化炭素排出量を削減できる。\"\n]","model":"gpt-4o-mini"}},{"step":"embedding","completed":"2024-09-24T18:38:50.639924","duration":1.543684,"params":{"source_code":"\nfrom langchain_community.embeddings import OpenAIEmbeddings\nfrom langchain_community.chat_models import ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"}},{"step":"clustering","completed":"2024-09-24T18:39:16.325395","duration":25.68476,"params":{"clusters":8,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # 必要なモジュールのインポート\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdの辞書パスを指定\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # 品詞フィルタリングを行うトークナイザー\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # 名詞、動詞、形容詞だけを抽出する\n            if node.feature.startswith('名詞') or node.feature.startswith('動詞') or node.feature.startswith('形容詞'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # 日本語のストップワードリストを作成（必要に応じて拡張可能）\n    japanese_stopwords = [\"これ\", \"それ\", \"あれ\", \"こと\", \"もの\", \"ため\", \"よう\", \"さん\", \"する\", \"なる\", \"ある\", \"いる\"]\n\n    # 日本語トークナイザーとストップワードを使用する\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # トピックモデルのフィッティング\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"}}],"end_time":"2024-09-24T18:46:39.767082"},"embedding":{"source_code":"\nfrom langchain_community.embeddings import OpenAIEmbeddings\nfrom langchain_community.chat_models import ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nあなたは、大学の役割や未来に関する広範なコンサルテーション内の一連の議論に対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。あなたには、相談の主な質問、クラスター内の議論のリスト、およびこのクラスター外の議論のリストが与えられます。あなたはクラスターを最もよく要約する1つの具体的で独自のカテゴリーラベルを回答します。\n\n質問からすでに明らかな文脈や「変革」「役割」という一般的なフレーズは含めないでください（例えば、相談の質問が「大学の未来における役割の変化とは何か」のようなものであれば、クラスターのラベルに「大学の未来における」「役割の変革」と繰り返す必要はありません）。\n\nラベルは非常に簡潔で、かつクラスターとその外側にある論点を区別するのに十分な正確さと具体性が必要です。以下のキーワードや視点（例えば、「デジタルトランスフォーメーション」「実務教育の強化」「国際連携の推進」「地域貢献の拡大」「学術の多様性」「学生のキャリア支援」「環境への取り組み」など）を参考に、クラスターを最もよく要約するラベルを作成してください。\n\n重要：ラベルは各クラスターの独自性を強調するものであり、そのクラスターの内部議論に基づいて具体的なキーワードを選んでください。\n\n/human\n\nコンサルテーションの質問: 「大学の未来における役割の変化とその影響は何だと思いますか？」\n\n関心のあるクラスター以外の論点の例\n\n * 地方大学と都市大学の教育格差の拡大。\n * オンライン教育の普及によるキャンパスの存在意義の変化。\n * 大学と企業の連携が進むことで、新しい研究開発モデルの登場。\n * 学費の高騰と教育機会の公平性に関する議論。\n * 国際的な大学ランキングにおける日本の大学の位置づけと評価。\n * 大学の持続可能性に対する社会的責任の強化。\n * 学生の価値観の変化による学問の選択傾向の変化。\n\nクラスター内部での議論の例\n\n * 大学の地域貢献が地元の経済や社会活動に大きな影響を与えている。\n * 学生のキャリア意識の高まりに伴い、大学での実務教育が重要視されている。\n * 研究開発とイノベーションの促進が、大学と地域社会の連携を強化している。\n * 海外の大学との連携を通じた国際的な学術交流が進んでいる。\n * 学生の多様性が増加する中で、大学教育のあり方が見直されている。\n * 大学の運営におけるデジタルトランスフォーメーションの必要性が高まっている。\n * 環境問題への取り組みが大学の使命に組み込まれつつある。\n\n/ai \n\n多様な学習環境と実務教育の強化","model":"gpt-4o-mini"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nあなたはシンクタンクで働くリサーチアシスタントのエキスパートです。さまざまなメディアソースや大学に関するインタビューのコメントのリストが渡されます。あなたは、主な要点を1~2段落にまとめて回答します。あなたは簡潔で読みやすい短い文章を書くことができます。 \n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o-mini"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。あなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。あなたの仕事は、その結果を簡潔にまとめることです。あなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。\nさらに、分析しているデータに基づいて、大学の将来に関する洞察を提供してください。高等教育の将来を形作る可能性のある新たな傾向、課題、機会を強調してください。分析では、進化する大学の状況に関連する、明確な将来展望を示す必要があります。","model":"gpt-4o-mini"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) > 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":false,"reason":"nothing changed"},{"step":"embedding","run":false,"reason":"nothing changed"},{"step":"clustering","run":false,"reason":"nothing changed"},{"step":"labelling","run":true,"reason":"some parameters changed: prompt"},{"step":"takeaways","run":false,"reason":"nothing changed"},{"step":"overview","run":true,"reason":"some dependent steps will re-run: labelling"},{"step":"aggregation","run":true,"reason":"some dependent steps will re-run: labelling, overview"},{"step":"visualization","run":true,"reason":"some dependent steps will re-run: aggregation"}],"status":"running","start_time":"2024-09-24T18:49:39.475549","completed_jobs":[{"step":"labelling","completed":"2024-09-24T18:49:49.301400","duration":9.820844,"params":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nあなたは、大学の役割や未来に関する広範なコンサルテーション内の一連の議論に対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。あなたには、相談の主な質問、クラスター内の議論のリスト、およびこのクラスター外の議論のリストが与えられます。あなたはクラスターを最もよく要約する1つの具体的で独自のカテゴリーラベルを回答します。\n\n質問からすでに明らかな文脈や「変革」「役割」という一般的なフレーズは含めないでください（例えば、相談の質問が「大学の未来における役割の変化とは何か」のようなものであれば、クラスターのラベルに「大学の未来における」「役割の変革」と繰り返す必要はありません）。\n\nラベルは非常に簡潔で、かつクラスターとその外側にある論点を区別するのに十分な正確さと具体性が必要です。以下のキーワードや視点（例えば、「デジタルトランスフォーメーション」「実務教育の強化」「国際連携の推進」「地域貢献の拡大」「学術の多様性」「学生のキャリア支援」「環境への取り組み」など）を参考に、クラスターを最もよく要約するラベルを作成してください。\n\n重要：ラベルは各クラスターの独自性を強調するものであり、そのクラスターの内部議論に基づいて具体的なキーワードを選んでください。\n\n/human\n\nコンサルテーションの質問: 「大学の未来における役割の変化とその影響は何だと思いますか？」\n\n関心のあるクラスター以外の論点の例\n\n * 地方大学と都市大学の教育格差の拡大。\n * オンライン教育の普及によるキャンパスの存在意義の変化。\n * 大学と企業の連携が進むことで、新しい研究開発モデルの登場。\n * 学費の高騰と教育機会の公平性に関する議論。\n * 国際的な大学ランキングにおける日本の大学の位置づけと評価。\n * 大学の持続可能性に対する社会的責任の強化。\n * 学生の価値観の変化による学問の選択傾向の変化。\n\nクラスター内部での議論の例\n\n * 大学の地域貢献が地元の経済や社会活動に大きな影響を与えている。\n * 学生のキャリア意識の高まりに伴い、大学での実務教育が重要視されている。\n * 研究開発とイノベーションの促進が、大学と地域社会の連携を強化している。\n * 海外の大学との連携を通じた国際的な学術交流が進んでいる。\n * 学生の多様性が増加する中で、大学教育のあり方が見直されている。\n * 大学の運営におけるデジタルトランスフォーメーションの必要性が高まっている。\n * 環境問題への取り組みが大学の使命に組み込まれつつある。\n\n/ai \n\n多様な学習環境と実務教育の強化","model":"gpt-4o-mini"}},{"step":"overview","completed":"2024-09-24T18:49:52.414168","duration":3.110486,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。あなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。あなたの仕事は、その結果を簡潔にまとめることです。あなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。\nさらに、分析しているデータに基づいて、大学の将来に関する洞察を提供してください。高等教育の将来を形作る可能性のある新たな傾向、課題、機会を強調してください。分析では、進化する大学の状況に関連する、明確な将来展望を示す必要があります。","model":"gpt-4o-mini"}}],"lock_until":"2024-09-24T18:54:52.418405","current_job":"aggregation","current_job_started":"2024-09-24T18:49:52.418373","current_job_progress":null,"current_jop_tasks":null}}},"__N_SSG":true}